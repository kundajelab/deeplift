class_mode: categorical
layers:
- W_constraint: null
  W_learning_rate_multiplier: null
  W_regularizer: null
  activation: linear
  activity_regularizer: null
  b_constraint: null
  b_learning_rate_multiplier: null
  b_regularizer: null
  border_mode: valid
  cache_enabled: true
  custom_name: convolution2d
  dim_ordering: th
  init: glorot_uniform
  input_shape: !!python/tuple [1, 4, 200]
  name: Convolution2D
  nb_col: 15
  nb_filter: 20
  nb_row: 4
  subsample: !!python/tuple [1, 1]
  trainable: true
- {cache_enabled: true, custom_name: prelu, init: zero, name: PReLU, trainable: true}
- border_mode: valid
  cache_enabled: true
  custom_name: maxpooling2d
  dim_ordering: th
  name: MaxPooling2D
  pool_size: &id001 !!python/tuple [1, 50]
  strides: *id001
  trainable: true
- {cache_enabled: true, custom_name: flatten, name: Flatten, trainable: true}
- W_constraint: {axis: 0, m: 7, name: MaxNorm}
  W_learning_rate_multiplier: null
  W_regularizer: null
  activation: linear
  activity_regularizer: {l1: 1.0e-07, l2: 0.0, name: ActivityRegularizer}
  b_constraint: null
  b_learning_rate_multiplier: null
  b_regularizer: null
  cache_enabled: true
  custom_name: dense
  init: glorot_uniform
  input_dim: null
  name: Dense
  output_dim: 200
  trainable: true
- {cache_enabled: true, custom_name: prelu, init: zero, name: PReLU, trainable: true}
- {cache_enabled: true, custom_name: dropout, name: Dropout, p: 0.3, trainable: true}
- W_constraint: {axis: 0, m: 7, name: MaxNorm}
  W_learning_rate_multiplier: null
  W_regularizer: null
  activation: linear
  activity_regularizer: {l1: 1.0e-07, l2: 0.0, name: ActivityRegularizer}
  b_constraint: null
  b_learning_rate_multiplier: null
  b_regularizer: null
  cache_enabled: true
  custom_name: dense
  init: glorot_uniform
  input_dim: null
  name: Dense
  output_dim: 200
  trainable: true
- {cache_enabled: true, custom_name: prelu, init: zero, name: PReLU, trainable: true}
- {cache_enabled: true, custom_name: dropout, name: Dropout, p: 0.3, trainable: true}
- {W_constraint: null, W_learning_rate_multiplier: null, W_regularizer: null, activation: linear,
  activity_regularizer: null, b_constraint: null, b_learning_rate_multiplier: null,
  b_regularizer: null, cache_enabled: true, custom_name: dense, init: glorot_uniform,
  input_dim: null, name: Dense, output_dim: 3, trainable: true}
- {activation: sigmoid, cache_enabled: true, custom_name: activation, name: Activation,
  trainable: true}
loss: binary_crossentropy
name: Sequential
optimizer: {beta_1: 0.8999999761581421, beta_2: 0.9990000128746033, epsilon: 1.0e-08,
  lr: 0.0010000000474974513, name: Adam}
