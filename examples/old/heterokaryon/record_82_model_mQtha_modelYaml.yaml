class_mode: categorical
layers:
- W_constraint: null
  W_learning_rate_multiplier: 10.0
  W_regularizer: null
  activation: linear
  activity_regularizer: null
  b_constraint: null
  b_learning_rate_multiplier: 1.0
  b_regularizer: null
  border_mode: valid
  cache_enabled: true
  custom_name: convolution2d
  dim_ordering: th
  init: glorot_uniform
  input_shape: !!python/tuple [1, 4, 2000]
  name: Convolution2D
  nb_col: 19
  nb_filter: 300
  nb_row: 4
  subsample: &id001 !!python/tuple [1, 1]
  trainable: true
- {axis: 1, cache_enabled: true, custom_name: batchnormalization, epsilon: 1.0e-06,
  mode: 0, momentum: 0.9, name: BatchNormalization, trainable: true}
- {activation: relu, cache_enabled: true, custom_name: activation, name: Activation,
  trainable: true}
- border_mode: valid
  cache_enabled: true
  custom_name: maxpooling2d
  dim_ordering: th
  name: MaxPooling2D
  pool_size: !!python/tuple [1, 3]
  strides: !!python/tuple [1, 3]
  trainable: true
- W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
  W_learning_rate_multiplier: 5.0
  W_regularizer: null
  activation: linear
  activity_regularizer: null
  b_constraint: null
  b_learning_rate_multiplier: 1.0
  b_regularizer: null
  border_mode: valid
  cache_enabled: true
  custom_name: convolution2d
  dim_ordering: th
  init: glorot_uniform
  input_shape: !!python/tuple [300, 1, 660]
  name: Convolution2D
  nb_col: 11
  nb_filter: 200
  nb_row: 1
  subsample: *id001
  trainable: true
- {axis: 1, cache_enabled: true, custom_name: batchnormalization, epsilon: 1.0e-06,
  mode: 0, momentum: 0.9, name: BatchNormalization, trainable: true}
- {activation: relu, cache_enabled: true, custom_name: activation, name: Activation,
  trainable: true}
- border_mode: valid
  cache_enabled: true
  custom_name: maxpooling2d
  dim_ordering: th
  name: MaxPooling2D
  pool_size: !!python/tuple [1, 4]
  strides: !!python/tuple [1, 4]
  trainable: true
- W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
  W_learning_rate_multiplier: 1.0
  W_regularizer: null
  activation: linear
  activity_regularizer: null
  b_constraint: null
  b_learning_rate_multiplier: 1.0
  b_regularizer: null
  border_mode: valid
  cache_enabled: true
  custom_name: convolution2d
  dim_ordering: th
  init: glorot_uniform
  input_shape: !!python/tuple [200, 1, 162]
  name: Convolution2D
  nb_col: 7
  nb_filter: 200
  nb_row: 1
  subsample: *id001
  trainable: true
- {axis: 1, cache_enabled: true, custom_name: batchnormalization, epsilon: 1.0e-06,
  mode: 0, momentum: 0.9, name: BatchNormalization, trainable: true}
- {activation: relu, cache_enabled: true, custom_name: activation, name: Activation,
  trainable: true}
- border_mode: valid
  cache_enabled: true
  custom_name: maxpooling2d
  dim_ordering: th
  name: MaxPooling2D
  pool_size: !!python/tuple [1, 4]
  strides: !!python/tuple [1, 4]
  trainable: true
- {cache_enabled: true, custom_name: flatten, name: Flatten, trainable: true}
- W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
  W_learning_rate_multiplier: 1.0
  W_regularizer: null
  activation: linear
  activity_regularizer: {l1: 1.0e-05, l2: 0, name: ActivityRegularizer}
  b_constraint: null
  b_learning_rate_multiplier: 1.0
  b_regularizer: null
  cache_enabled: true
  custom_name: dense
  init: glorot_uniform
  input_dim: null
  input_shape: !!python/tuple [1000]
  name: Dense
  output_dim: 1000
  trainable: true
- {cache_enabled: true, custom_name: prelu, init: zero, name: PReLU, trainable: true}
- {cache_enabled: true, custom_name: dropout, name: Dropout, p: 0.3, trainable: true}
- W_constraint: {axis: 0, m: 7.0, name: MaxNorm}
  W_learning_rate_multiplier: 1.0
  W_regularizer: null
  activation: linear
  activity_regularizer: {l1: 1.0e-05, l2: 0, name: ActivityRegularizer}
  b_constraint: null
  b_learning_rate_multiplier: 1.0
  b_regularizer: null
  cache_enabled: true
  custom_name: dense
  init: glorot_uniform
  input_dim: null
  input_shape: !!python/tuple [1000]
  name: Dense
  output_dim: 1000
  trainable: true
- {cache_enabled: true, custom_name: prelu, init: zero, name: PReLU, trainable: true}
- {cache_enabled: true, custom_name: dropout, name: Dropout, p: 0.3, trainable: true}
- W_constraint: null
  W_learning_rate_multiplier: 1.0
  W_regularizer: null
  activation: linear
  activity_regularizer: null
  b_constraint: null
  b_learning_rate_multiplier: 1.0
  b_regularizer: null
  cache_enabled: true
  custom_name: dense
  init: glorot_uniform
  input_dim: null
  input_shape: !!python/tuple [1000]
  name: Dense
  output_dim: 25
  trainable: true
- {activation: sigmoid, cache_enabled: true, custom_name: activation, name: Activation,
  trainable: true}
loss: weighted_binary_crossentropy
name: Sequential
optimizer: {beta_1: 0.8999999761581421, beta_2: 0.9990000128746033, epsilon: 1.0e-08,
  lr: 0.0010000000474974513, name: Adam}
